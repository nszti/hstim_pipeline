{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to HeureCa !","text":"<p>A modular data processing pipeline designed for analysing 2-photon calcium imaging and electrical stimulation experiments created for Hyperstim. This site contains detailed documentation for the analysis pipeline</p>"},{"location":"index.html#what-youll-find-here","title":"\ud83d\udcd6 What You'll Find Here","text":"<ul> <li>Setup: Step-by-step instructions to set up and run the pipeline.</li> <li>Descriptions: Overview of the available Python modules and functions.</li> </ul>"},{"location":"index.html#about-the-project","title":"\ud83d\udd2c About the Project","text":"<p>This pipeline supports the analysis of multi-session two-photon imaging experiments, including:</p> <ul> <li>Extraction and preprocessing of MESc TIFF files</li> <li>Suite2p-based ROI detection and signal extraction</li> <li>Automated activation analysis and visualization</li> <li>ROI tracking across sessions using CellReg</li> </ul>"},{"location":"index.html#technologies-used","title":"Technologies Used","text":"<ul> <li>Python 3.9, Suite2p</li> <li>MATLAB with CellReg</li> <li>Anaconda for environment management</li> <li>MkDocs for documentation</li> </ul> Note: This documentation is generated using MkDocs, a static site generator that uses Markdown files. Commands for MkDocs development      - mkdocs new [dir-name] - Create a new project.      - mkdocs serve - Start the live-reloading docs server.      - mkdocs build - Build the documentation site.       - mkdocs -h - Print help message and exit.       - mkdocs gh-deploy - Deploy the documentation to GitHub Pages.   <p>Use the sidebar navigation or the links above to get started.</p>      Created by Eszter Nguyen | 2025     GitHub | Email"},{"location":"documentation/api.html","title":"Modul &amp; Function Descriptions","text":"<p>This document describes the main Python modules and functions used in the calcium imaging and electrical stimulation data pipeline.</p>"},{"location":"documentation/api.html#pipeline_scriptpy","title":"<code>pipeline_script.py</code>","text":"<p>The main script to run the data processing pipeline. Configure paths and parameters here. The meaning of changeable values are explained more within the script.</p>"},{"location":"documentation/api.html#pre-process-section","title":"Pre-process section","text":"<ul> <li><code>RUN_MESC_PREPROCESS</code>: calls <code>mesc_tiff_extract.analyse_mesc_file()</code></li> <li><code>RUN_PREPROCESS</code>: runs <code>frequency_to_save.frequency_electrodeRoi_to_save</code>, <code>mesc_data_handling.tiff_merge</code>, <code>mesc_data_handling.extract_stim_frame</code></li> <li><code>S2P</code>: runs <code>suite2p_script.run_suite2p()</code></li> </ul>"},{"location":"documentation/api.html#analysis-section","title":"Analysis section","text":"<ul> <li><code>RUN_ANALYSIS_PREP</code>: calls various analysis-related functions from <code>functions.py</code></li> <li><code>PLOTS</code>, <code>PLOT_BTW_EXP</code>: control plotting and further calculations for analysis</li> </ul>"},{"location":"documentation/api.html#cellreg-section","title":"CellReg section","text":"<ul> <li><code>RUN_CELLREG_PREP</code>, <code>RUN_CELLREG</code>, <code>RUN_CELLREG_ANALYSIS</code> : CellReg-related processes like <code>.mat</code> file creation, running CellReg, and analyzing overlaps</li> </ul>"},{"location":"documentation/api.html#generalpy","title":"<code>general.py</code>","text":"<p>Contains utility functions for the TIFF extraction from MESc: - <code>ascii_to_str</code>: converts arrays of ASCII codes to strings - <code>find_frame_index_from_timestamp</code>: timing data to frame indices</p>"},{"location":"documentation/api.html#mesc_loaderpy","title":"<code>mesc_loader.py</code>","text":"<p>Parses <code>.mesc</code> file metadata using <code>xmltodict</code> to extract imaging parameters. Includes hardcoded test paths that should be customised.</p>"},{"location":"documentation/api.html#mesc_tiff_extractpy","title":"<code>mesc_tiff_extract.py</code>","text":""},{"location":"documentation/api.html#analyse_mesc_file","title":"<code>analyse_mesc_file()</code>","text":"<p>Extracts TIFF images, saves <code>mesc_data.npy</code>, <code>trigger.txt</code>, <code>fileId.txt</code>, <code>frameNo.txt</code>. Uses the function <code>extract_useful_xml_params()</code> from the python file <code>mesc_loader</code>. NB! Don\u2019t forget to check the <code>stim_trig_channel</code> value and match it to the MESc recordings.</p>"},{"location":"documentation/api.html#frequency_to_savepy","title":"<code>frequency_to_save.py</code>","text":""},{"location":"documentation/api.html#frequency_electroderoi_to_save","title":"<code>frequency_electrodeRoi_to_save()</code>","text":"<p>Saves frequency and electrode ROI info into <code>.npy</code> files. Saves electrode ROI info: all zeros automatically into <code>ELECTRODE_ROIS.NPY</code> Saves frequency info: into <code>FREQUENCIES.NYP</code>: have 3 options (single frequency for all, repeating pattern, manual enter) on how to fill the container, which will be asked in the command line.</p>"},{"location":"documentation/api.html#mesc_data_handlingpy","title":"<code>mesc_data_handling.py</code>","text":""},{"location":"documentation/api.html#tiff_merge","title":"<code>tiff_merge()</code>","text":"<p>Merges multiple TIFFs based on experimental parameters, needs <code>mesc_data.npy</code> to match file names with frequency positions. Saves merged TIFFs and associated frequency and ROI info.</p> <p>It creates the <code>merged_tiffs</code> folder, receives the numbers given in <code>pipeline_script.py</code> and merges (concatenates) the corresponding tiffs, which are saved to their own separate folders. The nomenclature of them as follows:  Folder name: <code>merged_expreimentname_MUnit_number1_number2</code> Tiff file name: <code>merged_expreimentname_MUnit_number1_number2.tif</code> If stimulation is <code>True</code>, it saves <code>SELECTED_FREQS.NPY</code> which uses FREQUENCIES (from Frequency_to_save) to save the corresponding frequencies.  And it also saves <code>SELECTED_ELEC_ROI.NPY</code> which is always the first ROI in the list, so the ROI with the number <code>0</code> ID. This part of the code was written at the beginning and is not often used.</p>"},{"location":"documentation/api.html#extract_stim_frame","title":"<code>extract_stim_frame()</code>","text":"<p>Saves <code>FRAMENUM.NPY</code> and <code>STIMTIMES.NPY</code> which are the frame numbers and the stimulation timepoints for the merged tiff files.</p>"},{"location":"documentation/api.html#suite2p_scriptpy","title":"<code>suite2p_script.py</code>","text":"<p>This script is based on the notebooks on the Github page of: Suite2p. The parameters for GCaMP6f &amp; GCaMP6s indicator are defined in it.  Additional explanations and descriptions of the parameter lists of functions are at the beginning of each script. </p>"},{"location":"documentation/api.html#run_suite2p","title":"<code>run_suite2p()</code>","text":"<p>This function runs Suite2p on the merged TIFF files with the base parameters defined in the documentations of Suite2p. In the if statements (gcamp == f &amp; gcamp == s) you can specify these parameters. Most of the time we modify the <code>threshold_scaling</code> and the <code>spatial_scale</code>. The <code>tau</code> is set according to the indicators already, but you can modify that as well if really needed.  The parameters are saved in the <code>suite2p_params.txt</code>.</p>"},{"location":"documentation/api.html#functionspy","title":"<code>functions.py</code>","text":"<p>This script contains various functions for data analysis and visualization. Each function is modular and can be called independently.</p>"},{"location":"documentation/api.html#stim_dur_val","title":"<code>stim_dur_val()</code>","text":"<p>Calculates and saves the stimulation duration for each merged TIFF file based on frequencies stored in <code>selected_freqs.npy</code> - Loads <code>selected_freqs.npy</code> from the corresponding folder. - Saves the result to <code>stimDurations.npy</code> to the same directory.</p>"},{"location":"documentation/api.html#electroderoi_val","title":"<code>electrodeROI_val()</code>","text":"<p>Saves the selected electrode ROI number into a file called <code>electrodeROI.npy</code>. - Needs <code>selected_elec_roi</code> as input, which is the integer ROI number designated as the electrode.</p>"},{"location":"documentation/api.html#dist_vals","title":"<code>dist_vals()</code>","text":"<p>Calculates and saves distances between ROIs and the electrode ROI.</p> <p>Extracts the ROI centroid coordinates (med) of all detected cells. Calculates the Euclidean distance between each ROI and a predefined electrode ROI. Saves results in both <code>.npy</code> and <code>.csv</code> formats. Output is: - <code>ROI_numbers.npy</code>: Contains the Suite2p ROI indices of all detected cells - <code>distances.npy</code>: Euclidean distances from each ROI to the electrode ROI - <code>elec_roi_info.csv</code>: Summary CSV file with ROI indices, centroid positions, electrode med position, and distances Attention: Suite2p saves the med in the format of (y,x) ! --&gt; <code>ROI_numbers.npy</code> is needed for further calculations in timecourse_val</p>"},{"location":"documentation/api.html#spontaneous_baseline_val","title":"<code>spontaneous_baseline_val()</code>","text":"<p>This function is for spontaneous recordings ( e.g.: chronic recording without stimulation). It calculates the baseline corrected traces using a pre-defined, fixed frame window &amp; plots and saves the calcium traces for a selected list of ROIs. - Output is <code>.svg</code> plots for each ROI in <code>list_of_roi_nums</code> &amp; <code>F0.npy</code> baseline-corrected trace</p>"},{"location":"documentation/api.html#baseline_val","title":"<code>baseline_val()</code>","text":"<p>Calculates F0 baseline before stim onset using <code>stimTimes.npy</code>. The baseline is defined as the period before the first stimulation time. - Needs <code>stimTimes.npy</code> which is saved in <code>extract_stim_frame</code> in <code>mesc_data_handling.py</code> - Output is <code>F0.npy</code> into the <code>suite2p/</code> directory.</p>"},{"location":"documentation/api.html#activated_neurons_val","title":"<code>activated_neurons_val()</code>","text":"<p>This function identifies activated neurons based on a statistical threshold applied to the fluorescence signal. It generates a list of activated ROIs and saves them in a CellReg-compatible <code>.mat</code> files. It also saves the <code>activated_neurons.npy</code> file which contains: <code>ROI_numbers</code>, <code>thresholds</code>, <code>activated_neurons</code></p> <p>Detects and saves activated neurons across stimulation blocks based on baseline corrected fluorescence and a statistical threshold (average of baseline period + standard deviation). Also creates a CellReg-compatible <code>.mat</code> file of activated ROI masks.  Usually good for experiments with multiple stimulation repeats and trials. Output is:   </p> <ul> <li><code>Activated_neurons.npy</code>: Contains a DataFrame with ROI numbers, calculated thresholds, and binary activation results for each ROI per stimulation repeat. </li> <li><code>*block*_cellreg_input.mat</code>: A CellReg-compatible mask stack of activated ROIs.</li> </ul>"},{"location":"documentation/api.html#timecourse_val","title":"<code>timecourse_val()</code>","text":"<p>Analyzes per-trial traces and stimulation effects across time. Analyzes calcium signal responses during stimulation and resting phases across multiple blocks and trials.   </p> <p>Output is:   </p> <ul> <li><code>results.npz</code>: A compressed NumPy file containing </li> <li><code>stimResults</code>: Binary array <code>[ROI, block, trial]</code> \u2014 <code>1</code> if above threshold during stimulation: </li> <li><code>restResults</code>: Binary array \u2014 <code>1</code> if above threshold during resting phase</li> <li><code>stimAvgs</code>: Mean \u0394F/F during stimulation </li> <li><code>restAvgs</code>: Mean \u0394F/F during rest</li> <li><code>baselineAvgs</code>: Baseline values per block per ROI</li> <li><code>full_trial_traces</code>: Concatenated trial traces (stim + rest) </li> </ul>"},{"location":"documentation/api.html#data_analysis_values","title":"<code>data_analysis_values()</code>","text":"<p>Generates multiple summary plots, e.g., active cell count, avg amplitude, etc.  </p> <p>Generates multiple <code>.svg</code> figures with subplots summarising activation results.  </p> <ul> <li>Number &amp; fraction of active neurons per block, Average calcium amplitudes across all ROIs for each block &amp; across all blocks for each trial, Trial-wise traces, Distance from electrode vs. response</li> <li>NB!: don\u2019t forget to update the legend values, because it can\u2019t plot the figures if there is a mismatch in the length of files &amp; legend values</li> </ul>"},{"location":"documentation/api.html#plot_stim_traces","title":"<code>plot_stim_traces()</code>","text":"<p>Analyses the calcium responses of a specific ROI and a population of neurons to electrical stimulation across trials. It extracts stimulus-locked traces, identifies activated ROIs, computes average responses, and generates visualisations and data files for further analysis or cell registration.  </p> <p>Calculations: </p> <p>Trace extraction </p> <ul> <li>For <code>roi_idx</code>, extracts a 4-second time window from the calcium traces (1s before to 3s after each stimulation) across all stimulations and repeats.</li> <li>Stores in <code>all_traces[repeat, stim_idx]</code>. ROI coordinate analysis: </li> </ul> <p>For each stimulation, computes the average (x, y) position of activated ROIs, but since then the CoM script was written which makes this part of the code redundant - Saves a <code>.csv</code> with average ROI coordinates per stimulation and repeat.  </p> <p>Distance from artificial origin:  Computes distances of all ROIs from an artificial origin (center of FOV).  </p> <ul> <li>Saves pixel distances in <code>dist_from_o_pix.txt</code>.</li> </ul> <p>Activation detection: </p> <p>For every valid ROI (<code>iscell==1</code>):  </p> <ul> <li>Computes the average signal during each stimulation window.</li> <li>Compares to a threshold: mean(baseline) + threshold_value \u00d7 std(baseline).</li> <li> <p>Saves binary activation (0/1) in <code>activation_results[roi_id][repeat][stim_idx]</code>. For every valid ROI (<code>iscell==1</code>):  </p> </li> <li> <p>Computes the average signal during each stimulation window.</p> </li> <li>Compares to a threshold: mean(baseline) + threshold_value \u00d7 std(baseline).</li> <li>Saves binary activation (0/1) in <code>activation_results[roi_id][repeat][stim_idx</code>].  </li> </ul> <p>The <code>activation_results</code> dictionary contains a binary value for each of the rois, <code>1</code> if the cell was activated and <code>0</code>, if it wasn\u2019t.</p> <p>Plot out activated neurons: </p> <p>Stim activation counts is redundant as well. In the <code>.csv</code> there is the list of rois which are activated per repeat.   </p> <p>CellReg-compatible output: Constructs binary masks of activated ROIs &amp; saves masks into <code>.mat</code> files under <code>cellreg_files/</code>. Activation summary: </p> <p>Optionally you can save the activation DataFrame as well, which contains the activation results: counts the number of activated ROIs per stim &amp; repeat. - Saves a <code>.csv</code> with lists and counts of activated ROIs (<code>stim_activation_counts_fileX.csv</code>).</p> <p>Extractin traces per amplitude: Creates <code>sum_avg_dir/</code> folder which contains the traces of rois per amplitude in <code>.npy</code> files, a <code>.csv</code> containing the average coordinates of the rois per repeat and stim, and a <code>.csv</code> containing the activation results per amplitude.</p> <p>Plots: </p>"},{"location":"documentation/api.html#roi_map_per_stimsvg","title":"<code>roi_map_per_stim.svg</code>","text":"<p>Grid of stimulation footprints: one subplot per (repeat \u00d7 stimulation), showing which ROIs were activated.</p>"},{"location":"documentation/api.html#stim_traces_gridsvg","title":"<code>stim_traces_grid.svg</code>","text":"<p>Calcium traces for <code>roi_idx</code>, organized by repeat and stim amplitude, with stimulation onset marked.</p>"},{"location":"documentation/api.html#overlapping_per_trial_for_roixpng","title":"<code>overlapping_per_trial_for_roiX.png</code>","text":"<p>Overlapping traces of <code>roi_idx</code> across all stimulations per repeat. Color-coded by amplitude.</p>"},{"location":"documentation/api.html#overlapping_per_param_for_roixpng","title":"<code>overlapping_per_param_for_roiX.png</code>","text":"<p>Overlapping traces of <code>roi_idx</code> across all repeats, grouped by stimulation amplitude.</p>"},{"location":"documentation/api.html#sum_avg_traces_subplotsvg","title":"<code>sum_avg_traces_subplot.svg</code>","text":"<p>Grand-average trace of all activated ROIs for each amplitude. One plot per amplitude.</p> <p>Saved files: </p>"},{"location":"documentation/api.html#csv","title":"<code>.csv:</code>","text":"<ul> <li><code>activation_results_fileX.csv</code>: binary activation per ROI.</li> <li><code>avg_x_y_per_repeat_stim_fileX.csv</code>: mean coordinates.</li> <li><code>stim_activation_counts_fileX.csv</code>: activation summary.</li> <li><code>activation_counts.csv</code>: total count of active ROIs per amplitude.</li> </ul>"},{"location":"documentation/api.html#npy","title":"<code>.npy:</code>","text":"<p>Grand average trace of activated ROIs per amplitude (sum_avg_XXuA.npy).</p>"},{"location":"documentation/api.html#mat","title":"<code>.mat:</code>","text":"<p>ROI masks for CellReg, saved per amplitude (pix_data_for_XXuA.mat, activated_mask_XXuA.mat)</p>"},{"location":"documentation/api.html#svg-png","title":"<code>.svg / .png:</code>","text":"<p>all plots</p>"},{"location":"documentation/api.html#plot_across_experiments","title":"<code>plot_across_experiments()</code>","text":"<p>Gets the data from the <code>sum_avg_dir/</code> folder which is created in <code>plot_stim_traces()</code>. Plots overlaid average calcium traces across multiple stimulation experiments, grouped by stimulation amplitude.  Loads previously saved average traces per stimulation amplitude (from <code>sum_avg_&lt;amplitude&gt;uA.npy</code> files) and overlays these traces in subplots.</p>"},{"location":"documentation/api.html#analyze_merged_activation_and_save","title":"<code>analyze_merged_activation_and_save()</code>","text":"<p>Analyses neuronal activity across multiple blocks and files, identifying activated neurons based on a statistical threshold applied to the fluorescence signal during stimulation periods.  The analysis is performed block by block using metadata files and preprocessed Suite2p outputs.  The difference between the previous functions is that you can modify stimulation parameter values &amp; suit it to multiple protocols (e.g.: it1\u2019s good for current steering experiments where there\u2019s 1 repeat of 10 trials) It also saves the results in a CellReg-compatible <code>.mat</code> file, which can be used for further analysis in CellReg.</p>"},{"location":"documentation/api.html#compy","title":"<code>CoM.py</code>","text":""},{"location":"documentation/api.html#inverse_distance_weighted_center_of_mass","title":"inverse_distance_weighted_center_of_mass()","text":"<p>Calculates the center of mass from a pre-defined center ( this is set to (0,0) which is the upper left corner of the FOV) </p>"},{"location":"documentation/api.html#plot_weighted_com","title":"plot_weighted_com()","text":"<p><code>coords_list</code> is an array which holds the med values of the activated rois as np.arrays within the individual blocks (tiffs), these values are from the <code>med_of_act_ns_[\u2026].csv</code> which is saved in the <code>analyze_merged_activation_and_save</code> function of <code>functions.py</code> file, so you have to run that first. (You can convert the <code>med_of_act_ns_[\u2026].csv</code> to a list of arrays with the help of ChatGPT really quickly.) In the <code>plot_order</code> list, you are to specify the order of recordings based on the experiment records. This is important because the plot is created according to the order of the files. Also pay attention to the inverted axis\u2019 (it\u2019s tricky because of Suite2p\u2019s <code>stat.npy</code> output. The y is inverted. So be sure to double check it and reference it back to the original recording.</p>"},{"location":"documentation/api.html#cellreg_processpy","title":"<code>cellreg_process.py</code>","text":"<p>Information on how to run CellReg from the MATLAB GUI is available here.</p>"},{"location":"documentation/api.html#suite2p_to_cellreg_masks","title":"<code>suite2p_to_cellreg_masks()</code>","text":"<p>Good for creating the <code>.mat</code> files from spontaneous recordings or single recordings (basically files which don\u2019t require any kind of additional calculations to separate stimulations)  Saves the result <code>.mat</code> files into the new <code>cellreg_files/</code> directory. </p>"},{"location":"documentation/api.html#cellreg_analysis_overlap","title":"cellreg_analysis_overlap()","text":"<p>After running CellReg it saves the <code>cellRegistered[date].mat</code> file which is a struct containing information from the cell registration procedure. Don\u2019t forget to update this file name, otherwise you\u2019ll get false results. This function uses <code>cell_to_index_map:</code> \u201cA matrix of size NxM, with the mapping of each registered cell to the indices in each registered session\u201d which we use to calculate the overlap between each session with a pairwise manner.  The output is the <code>session_pair_overlap.csv</code> which contains A &amp; B compared sessions, the number of overlapped cells and the percentage of this number compared to the whole. </p>"},{"location":"documentation/api.html#single_block_activation","title":"<code>single_block_activation()</code>","text":"<p>Based on the given parameters, it calculates the activated cells for each stimulation set and saves the <code>.mat</code>files for them.  This function was written before <code>analyze_merged_activation_and_save()</code> in <code>functions.py</code>, so since then this is made redundant. But it can still be useful if you want to only save the <code>.mat</code> files.</p>"},{"location":"documentation/api.html#cellreg_analysispy","title":"<code>cellreg_analysis.py</code>","text":""},{"location":"documentation/api.html#run_cellreg_matlab","title":"run_cellreg_matlab():","text":"<p>This is where the magic happens. If that is done then you only need to run this function to run the CellReg analysis. 1. Check in the script if the path to the MATLAB script is correct. 2. Make sure the data_path and the other values are correct, and then you can run the Matlab script from Python.</p> <p>Note: Many functions save data in <code>.npy</code>, <code>.csv</code>, <code>.svg</code>, <code>.mat</code> formats as part of the pipeline's modular output. Please also look at the functions carefully, because there are a lot of containers which can be saved optionally, but right, now those lines are commented out.</p>"},{"location":"documentation/runs.html","title":"Examples","text":""},{"location":"documentation/runs.html#this-page-provides-examples-on-how-to-run-the-pipeline-for-different-experimental-conditions","title":"This page provides examples on how to run the pipeline for different experimental conditions.","text":""},{"location":"documentation/runs.html#note-this-is-still-under-revision","title":"Note: This is still under revision","text":"<p>Spontaneous Activity Recordings You can leave out any part which need stimulation times for calculation. This usually leaves us with the following functions: <code>mesc_tiff_extract.analyse_mesc_file()</code> <code>mesc_data_handling.tiff_merge(stimulation=False)</code> <code>suite2p_script.run_suite2p()</code> <code>functions.spontaneous_baseline_val()</code> <code>cellreg_preprocess.suite2p_to_cellreg_masks()</code> <code>cellreg_analysis.run_cellreg_matlab()</code></p>"},{"location":"documentation/runs.html#example-code","title":"example code:","text":"<pre><code>mesc_tiff_extract.analyse_mesc_file(Path(root_directory)/mesc_file_name, root_directory, print_all_attributes=True, plot_curves = True)\nmesc_data_handling.tiff_merge(mesc_file_name, list_of_file_nums, root_directory, False)\nsuite2p_script.run_suite2p(tiff_directory, list_of_file_nums, False, gcamp) \n\n</code></pre> <p>\"Validation\" Experiments</p>"},{"location":"documentation/runs.html#as-a-rule-of-thumb-we-can-say-that-any-function-with-the-_val-suffix-is-used-for-validation-experiments-and-has-been-developed-thus-replaced-with-other-functions-in-case-of-the-more-advanced-experiments","title":"As a rule of thumb, we can say that any function with the <code>_val()</code> suffix is used for validation experiments and has been developed, thus replaced with other functions in case of the more advanced experiments.","text":"<p><code>functions.stim_dur_val()</code> <code>funcitons.electROI_val()</code> <code>functions.dist_val()</code> <code>functions.balseine_val()</code> <code>functions.activated_neurons_val()</code> <code>functions.timecourse_vals()</code> <code>functions.data_analysis_values()</code></p>"},{"location":"documentation/runs.html#in-case-of-overlap-footprint","title":"in case of overlap footprint","text":"<p><code>cellreg_preprocess.suite2p_to_cellreg_mask()</code></p> <p>Advanced Experiments Experiments where one set of parameters is recorded in 1 recording (usually bipolar stimulation experiments). So there is no need to concatenate the tiffs, you can handle them individually and stimulation calculations can be made from the first calculation timepoint. You can use the following functions: <code>mesc_tiff_extract.analyse_mesc_file()</code> <code>frequency_to_save.frequency_electrodeRoi_to_save()</code> <code>mesc_data_handling.tiff_merge(stimulation=True)</code> <code>mesc_data_handling.extract_stim_frame()</code> <code>suite2p_script.run_suite2p()</code> <code>functions.baseline_val()</code> <code>functions.plot_stim_traces()</code> - Pay attention to the parameter values.  <code>cellreg_preprocess.run_cellreg_matlab()</code> <code>cellreg_preprocess.cellreg_analysis_overlap()</code></p> <p>Current steering Experiments  Similarly to bipolar experiments, in current steering experiments we usually have 1 recording for one set of parameters. In these cases usually you can run the following functions:  <code>mesc_tiff_extract.analyse_mesc_file()</code> <code>mesc_data_handling.tiff_merge(stimulation=True)</code> <code>suite2p_script.run_suite2p()</code> <code>functions.baseline_val()</code> <code>functions.analyze_merged_activation_and_save()</code> <code>CoM.plot_weighted_com()</code>- Pay attention to the plot order <code>cellreg_preprocess.run_cellreg_matlab()</code> <code>cellreg_preprocess.cellreg_analysis_overlap()</code></p>"},{"location":"documentation/structure.html","title":"Structure","text":"<p>This page os meant to show the real structure of the pipeline, so that running the pipeline is easier to understand.</p>"},{"location":"documentation/structure.html#the-overall-structure-of-the-data-created-by-heureca","title":"The overall structure of the data created by HeureCa:","text":"<pre><code>&lt;root_directory&gt;/\n\u251c\u2500\u2500 &lt;experiment_name&gt;_1.tif\n\u251c\u2500\u2500 &lt;experiment_name&gt;_2.tif\n\u251c\u2500\u2500 &lt;experiment_name&gt;.mesc\n\u2514\u2500\u2500 merged_tiffs/\n    \u251c\u2500\u2500 merged_&lt;group_1&gt;/\n    \u2502   \u2514\u2500\u2500 merged_&lt;group_1&gt;.tif\n    \u251c\u2500\u2500 merged_&lt;group_2&gt;/\n    \u2502   \u2514\u2500\u2500 merged_&lt;group_2&gt;.tif\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"documentation/structure.html#concrete-directory-structure","title":"Concrete directory structure:","text":"<p>Here's a simplified layout of the folder structure for Hyperstim's data:</p> <pre><code>Hyperstim\n\u2514\u2500\u2500 data_analysis/\n        \u2514\u2500\u2500 &lt;experiment_name&gt;/\n            \u251c\u2500\u2500 merged_tiffs/\n            \u2502   \u251c\u2500\u2500 merged_&lt;experiment_name&gt;/\n            \u2502   \u2502   \u2514\u2500\u2500 merged_&lt;experiment_name&gt;&lt;concatenated tiff numbers&gt;.tif\n            \u2502   \u2502           \u2514\u2500\u2500 suite2p/\n            \u2502   \u2502               \u2514\u2500\u2500 plane0/\n            \u2502   \u2502                   \u251c\u2500\u2500 data.bin\n            \u2502   \u2502                   \u251c\u2500\u2500 F.npy\n            \u2502   \u2502                   \u251c\u2500\u2500 ops.npy\n            \u2502   \u2502                   \u251c\u2500\u2500 stat.npy\n            \u2502   \u2502                   \u251c\u2500\u2500 iscell.npy\n            \u2502   \u2502                   \u251c\u2500\u2500 spks.npy\n            \u2502   \u2502                   \u251c\u2500\u2500 iscell.npyFneu\n            \u2502   \u2502                   \u251c\u2500\u2500 Fall.npy\n            \u2502   \u2502                   \u2514\u2500\u2500 F0.npy\n            \u2502   \u2514\u2500\u2500 cellreg_files/\n            \u2502       \u2514\u2500\u2500 cellreg_files/\n            \u2502               \u251c\u2500\u2500 cellreg_input_&lt;experiment_name&gt;_&lt;tif number&gt;.mat\n            \u2502               \u2514\u2500\u2500 Figures/\n            \u251c\u2500\u2500 trigger.txt\n            \u251c\u2500\u2500 stim.txt\n            \u251c\u2500\u2500 frameNo.txt\n            \u251c\u2500\u2500 fileID.txt\n            \u2514\u2500\u2500 &lt;experiment_name&gt;.mesc\n</code></pre>"},{"location":"documentation/structure.html#in-summary","title":"In summary:","text":"<ul> <li><code>root_directory</code> is the main directory where all your experiment data is stored</li> <li>Each experiment has its own folder, which contains the original TIFF files, the <code>.mesc</code> file, and a <code>merged_tiffs</code> folder.</li> <li>The <code>merged_tiffs</code> folder contains subfolders for each group of merged TIFF files, where each subfolder has a merged TIFF file named according to the group. Each merged TIFF file has its own Suite2p output directory (if suite2p has been run on the file) containing the necessary files for analysis.</li> <li>The cellreg files are stored in a separate <code>cellreg_files</code> folder, which contains the input <code>.mat</code> files for CellReg and the generated figures separately in the <code>Figures</code> folder (generated by the CellReg pipeline).</li> </ul>"},{"location":"setup/help.html","title":"Help to avoid errors:","text":"<ul> <li>Suite2p only works with Python version 3.9</li> <li>Codes are best to run with the suite2p interpreter</li> <li>It is important to have the <code>.suite2p</code> folder in the package to be able to access the default <code>ops</code> dictionary</li> </ul>"},{"location":"setup/help.html#error-solutions","title":"Error solutions:","text":"<ul> <li>Managing <code>typeDict</code> error: <code>conda install h5py</code>, also make sure suite2p foler is in the proper path.</li> <li>If <code>mesc_tiff_extract.py</code> gives the error: <code>handling multiple msession file is not supported</code>. It's most likely that the file name is not correct.  </li> <li>Python version: <code>3.9</code></li> <li><code>Zc.lockfile module</code> error: run from the command line: <code>pip install zc-lockfile</code></li> </ul>"},{"location":"setup/interpreter.html","title":"\ud83d\udee0\ufe0f Git &amp; PyCharm Setup Guide","text":"<p>Follow these steps to set up your cloned GitHub project in PyCharm and ensure Git is properly configured.</p>"},{"location":"setup/interpreter.html#0-clone-the-repository-if-not-done-yet","title":"0. Clone the Repository (if not done yet)","text":"<p>Use Git Bash or your terminal:</p> <pre><code>git clone https://github.com/your-username/your-repo.git\n</code></pre> <p>This will create a folder named <code>your-repo</code>.</p>"},{"location":"setup/interpreter.html#1-open-the-project-in-pycharm","title":"1. Open the Project in PyCharm","text":"<ul> <li>Launch PyCharm</li> <li>Select \u201cOpen\u201d from the welcome screen (or go to File &gt; Open...)</li> <li>Navigate to the folder where your GitHub repo is cloned</li> <li>Click Select Folder \u2192 choose This Window or New Window to open the project.</li> </ul>"},{"location":"setup/interpreter.html#2-make-sure-git-is-recognised","title":"2. Make Sure Git is Recognised","text":"<ul> <li>Go to File &gt; Settings (or PyCharm &gt; Preferences on macOS)</li> <li>Navigate to Version Control &gt; Git</li> <li>Ensure the path to Git executable is correct. Click Test to verify</li> </ul>"},{"location":"setup/interpreter.html#3-enable-version-control-integration","title":"3. Enable Version Control Integration","text":"<p>If PyCharm doesn't automatically detect Git:</p> <ul> <li>Go to VCS &gt; Enable Version Control Integration (only appears if Git isn't yet detected, otherwise you\u2019ll see Git)</li> <li>Select Git from the list and click OK</li> </ul>"},{"location":"setup/interpreter.html#4-check-the-git-remote","title":"4. Check the Git Remote","text":"<p>To verify the remote origin (connection to GitHub):</p> <ul> <li>Go to Git &gt; Manage Remotes</li> <li>Or open the Terminal and run:</li> </ul> <pre><code>git remote -v\n</code></pre> <p>You should see:</p> <pre><code>origin  https://github.com/your-username/your-repo.git (fetch)\norigin  https://github.com/your-username/your-repo.git (push)\n</code></pre> <p>If it's missing, add it manually from the terminal:</p> <pre><code>git remote add origin https://github.com/your-username/your-repo.git\n</code></pre> <p>This ensures that your Git integration is ready to use for commits, pushes, and GitHub Pages deployment.</p>"},{"location":"setup/matlab_integration.html","title":"MATLAB Engine API Setup for PyCharm Integration","text":"<p>This guide explains how to run a MATLAB <code>.m</code> script from a Python <code>.py</code> script using the MATLAB Engine API in PyCharm.</p>"},{"location":"setup/matlab_integration.html#outlook","title":"Outlook","text":"<p>I took this video as a starting point, tried both ways, but found the Matlab engine API the feasible method. (however you\u2019re more than welcome to solve the other one) Let\u2019s assume \u2018main.py\u2019 is the main Python file which runs your Python project &amp; \u2018main.m\u2019 is the main Matlab file which you\u2019d like to run in PyCharm. For this, you need to  1) put the \u2018main.m\u2019 file in the same folder as the \u2018main.py\u2019, 2) connect Matlab with PyCharm with a Matlab Engine API for Python, 3) import the Matlab engine into the \u2018main.py\u2019 and call the Matlab code.  Keep in mind, that for this method, you need Matlab to be installed. </p>"},{"location":"setup/matlab_integration.html#step-0-version-compatibility","title":"Step 0: Version Compatibility","text":"<ul> <li>First and foremost, check the version of Python which you\u2019re working with. (If you're working in .venv, check that as well and take that into account too). Also check that you\u2019re working with a 64 bit version of Python to match the architecture of Matlab.</li> <li>Check your Matlab release version too. </li> <li>Crucial step!: Check the compatibility of your Python and Matlab here.</li> </ul>"},{"location":"setup/matlab_integration.html#step-1-install-matlab-engine-api","title":"Step 1: Install MATLAB Engine API","text":"<ol> <li>The matlab engine API is within the installed MATLAB package. To avoid any permission errors and other issues  run cmd as an Administrator (OR if you\u2019re running your \u2018main.py\u2019 from a virtual environment -in my case anaconda3- open anaconda prompt as an Administrator).</li> <li>While in the virtual environment, direct to the API folder, which is usually in the following path:</li> </ol> <pre><code>C:\\Program Files\\MATLAB\\[your_version]\\extern\\engines\\python\n</code></pre> <p>If you direct to this path, you should see the \u2018setup.py\u2019 file. 3. In the command line, install this with the following command:</p> <pre><code>python setup.py install\n</code></pre> <p>For alternative installation methods, refer to the official guide.</p>"},{"location":"setup/matlab_integration.html#step-2-place-m-and-py-files-are-in-the-same-folder","title":"Step 2: Place <code>.m</code> and <code>.py</code> Files are in the same folder","text":"<p>Put your <code>main.m</code> file in the same folder where you run your <code>main.py</code> file from.</p>"},{"location":"setup/matlab_integration.html#step-3-import-the-mainengine","title":"Step 3: Import the <code>main.engine</code>","text":"<p>In your <code>main.py</code>:</p> <pre><code>import matlab.engine\n</code></pre> <p>If you get the `No module named 'matlab' error, then your API installation wasn\u2019t successful:((  Check if you installed the engine to the right path.</p>"},{"location":"setup/matlab_integration.html#step-4-test-the-connection","title":"Step 4: Test the Connection","text":"<p>Check if you were successful and matlab is connected to PyCharm with the following code: You can also see how you can start the engine here.</p> <pre><code>import matlab.engine\neng = matlab.engine.start_matlab()\neng.eval(\"disp('Connected to MATLAB')\", nargout=0)\neng.quit()\n</code></pre>"},{"location":"setup/matlab_integration.html#step-5-pass-parameters-from-python-to-matlab","title":"Step 5: Pass Parameters from Python to MATLAB","text":"<p>So far, the setup can run a MATLAB code, but can not overwrite the variables dynamically. To overwrite a variable in Python and ensure MATLAB uses it when you call the MATLAB function via the API, you can pass it as an argument to your MATLAB function.</p> <p>Theoretically, the other option would be to assign it directly in the MATLAB workspace with <code>eng.workspace[\u2018data_path\u2019] = \u2026</code></p> <p>HOWEVER for me, it resulted in an error saying unrecognised function or variable, which confirms that (in this case) <code>data_path</code> is not visible in the function scope of the MATLAB script. This presumably is because variables set in the MATLAB base workspace (via Python eng.workspace['...'] = ...) are not automatically visible inside the functions. Therefore, we\u2019re left with passing the variables as arguments. For this, you have to modify the code to a function that accepts the data_path and other variables as inputs. (make sure you don\u2019t clear the assigned variables).</p>"},{"location":"setup/matlab_integration.html#step-6-run-the-python-code","title":"Step 6: Run the Python Code","text":"<p>Run the MATLAB code via the API, you can call the MATLAB script as if it were a Python function with:</p> <pre><code> eng.[matlab_script_name ](params, nargout = 0)\n</code></pre>"},{"location":"setup/matlab_integration.html#done","title":"\ud83c\udf89 Done!","text":"<p>Congratulations \u2014 your Python project now integrates MATLAB! \ud83e\udd2f\ud83e\udd73</p>"},{"location":"setup/usage.html","title":"Setup Guide","text":"<p>This guide walks you through the setup and usage of the calcium imaging and stimulation data pipeline.</p>"},{"location":"setup/usage.html#prerequisites","title":"\ud83d\udce6 Prerequisites","text":"<p>Before you begin, make sure the following are installed:</p> <ul> <li>Git</li> <li>Anaconda (recommended for managing Python environments)</li> <li>MATLAB (recommended versions: 2021b to 2023a)</li> <li>Also install the Parallel Computing Toolbox for CellReg</li> <li>Python IDE (e.g., PyCharm)</li> </ul>"},{"location":"setup/usage.html#repository-setup","title":"\ud83d\udcc1 Repository Setup","text":""},{"location":"setup/usage.html#clone-the-repository","title":"Clone the Repository","text":"<p>Open Git Bash or your terminal and run:</p> <pre><code>git clone https://github.com/nszti/hstim_pipeline.git\ncd hstim_pipeline\n</code></pre> <p>You should now see the <code>hstim_pipeline</code> folder in your working directory.</p>"},{"location":"setup/usage.html#project-structure","title":"\ud83e\uddf1 Project Structure","text":"<p>Here's a simplified layout of the project:</p> <pre><code>Hyperstim/pipeline_pending/\n\u251c\u2500\u2500 pipeline_script.py\n\u251c\u2500\u2500 mesc_loader.py\n\u251c\u2500\u2500 general.py\n\u251c\u2500\u2500 package_for_pipeline/\n\u2502   \u251c\u2500\u2500 CoM.py\n\u2502   \u251c\u2500\u2500 cellreg_analysis.py\n\u2502   \u251c\u2500\u2500 cellreg_process.py\n\u2502   \u251c\u2500\u2500 frequency_to_save.py\n\u2502   \u251c\u2500\u2500 functions.py\n\u2502   \u251c\u2500\u2500 mesc_data_handling.py\n\u2502   \u251c\u2500\u2500 mesc_tiff_extract.py\n\u2502   \u251c\u2500\u2500 suite2p_script.py\n\u2502   \u2514\u2500\u2500 tiff_merge.py\n\u2514\u2500\u2500 hdf5io/\n    \u2514\u2500\u2500 setup.py\n</code></pre>"},{"location":"setup/usage.html#python-environment-setup","title":"\ud83d\udc0d Python Environment Setup","text":"<p>The environment includes dependencies for Suite2p and the custom pipeline scripts.</p>"},{"location":"setup/usage.html#step-by-step","title":"Step-by-Step:","text":"<ol> <li>Open your terminal / Anaconda Prompt</li> <li>Navigate to the repository directory containing:    <code>bash    environment.yml</code></li> <li>Create the Conda environment (this may take a few minutes):</li> <li>First, make sure there is no environment with the same name, then use the command:    <code>bash    conda env create -f environment.yml</code></li> <li>You'll probably get <code>FutureWarning</code> messages about the <code>conda</code> command, but you can ignore them as it will create the environment anyway.</li> <li>Activate it:    <code>bash    conda activate suite2p</code></li> <li>Verify Suite2p is installed:    <code>bash    suite2p --version    python -m suite2p</code></li> <li>You can open the Suite2p GUI with the command:    <code>bash    python -m suite2p</code></li> </ol>"},{"location":"setup/usage.html#ide-setup-pycharm-recommended","title":"\ud83d\udda5\ufe0f IDE Setup (PyCharm Recommended)","text":""},{"location":"setup/usage.html#connect-conda-environment","title":"Connect Conda Environment","text":"<p>Please see here, the detailed instructions to connect the Conda environment to your IDE, but here's a quick summary for PyCharm:  </p> <ol> <li>Open PyCharm</li> <li>Go to Project &gt; Python Interpreter</li> <li>Click Add Interpreter</li> <li>Select Add Local Interpreter</li> <li>Choose Conda and select the <code>suite2p</code> environment</li> <li>Click OK and wait for it to load the packages</li> </ol> <p>Now your IDE should be able to run the Python-based parts of the pipeline.</p>"},{"location":"setup/usage.html#matlab-cellreg-setup","title":"\ud83e\uddec MATLAB + CellReg Setup","text":"<p>Cellreg intorduction: CellReg is a package we use for the tracking of neurons between multiple sessions (recordings, tiffs) and find the overlap between sessions. It is mostly working, but has some bugs which we\u2019re yet to understand. CellReg is matlab based, so the functions in the pipeline have the purpose of creating the .mat files needed for cellreg\u2019s input.   </p> <p>Namely: \u201cmatrices of spatial footprints of cellular activity (ROIs) of the cells that were detected separately in the different sessions\u201d  The dimensions of said matrices translated into Suite2p outputs: <code>[nROIs, Ly, Lx]</code>.  So the needed outputs of Suite2p for generating CellReg inputs are: <code>ops.npy</code> for <code>Ly</code> and <code>Lx</code> dimensions, <code>stat.npy</code> for pixel information, <code>iscell.npy</code> for ROI information.</p> <p>Run cellreg manually: </p> <p>First make sure to add to path all the folders and subfolders of CellReg in Matlab.  Then, in the MATLAB GUI:  </p> <p><code>CellReg.m</code> run \u2192 in GUI load new data: select the <code>.mat</code> files for sessions &amp; give 1.07 micron for pixel size \u2192 run Non-rigid alignment \u2192 run probabilistc modeling  with 12 microns \u2192 from here just run the next part of the pipeline</p> <p>Since CellReg is MATLAB-based:</p> <ul> <li>Download and install CellReg</li> <li>Add all folders and subfolders of CellReg to the MATLAB path</li> <li>Use the MATLAB GUI to:</li> <li>Load sessions</li> <li>Run non-rigid alignment</li> <li>Run probabilistic modeling (12 microns pixel size)</li> </ul> <p>Full instructions are available in the official CellReg documentation.</p> <p>Once setup is complete, continue to the <code>pipeline_script.py</code> to run the analysis.</p>"}]}